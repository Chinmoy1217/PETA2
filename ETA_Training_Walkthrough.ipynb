{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# ETA-Insight: Multi-Model Evaluation & Advanced Visualization\n",
                "\n",
                "This notebook trains and compares **4 Models** on the augmented 600k dataset:\n",
                "1.  **XGBoost** (Gradient Boosting)\n",
                "2.  **LightGBM** (Gradient Boosting - Fast)\n",
                "3.  **Random Forest** (Bagging - Strong Baseline)\n",
                "4.  **Linear Regression** (Baseline - Simple)\n",
                "\n",
                "It also includes advanced visualizations:\n",
                "-   **Mode-wise Accuracy**: Boxplots showing error distribution for Air vs. Rail vs. Road.\n",
                "-   **Feature Importance**: What drives the ETA?\n",
                "-   **Residual Analysis**: Are errors random or biased?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "import numpy as np\n",
                "import xgboost as xgb\n",
                "import lightgbm as lgb\n",
                "from sklearn.linear_model import LinearRegression\n",
                "from sklearn.ensemble import RandomForestRegressor\n",
                "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
                "from sklearn.preprocessing import LabelEncoder\n",
                "from sklearn.model_selection import train_test_split\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "pd.set_option('display.max_columns', None)\n",
                "sns.set_style(\"whitegrid\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Load Data & Preprocess"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "def load_and_preprocess():\n",
                "    file_path = 'Cleaned_Training_Data_Augmented.csv'\n",
                "    print(f\"Loading: {file_path}\")\n",
                "    df = pd.read_csv(file_path)\n",
                "    \n",
                "    # Split\n",
                "    train, val = train_test_split(df, test_size=0.2, random_state=42)\n",
                "    print(f\"Training: {len(train)} | Validation: {len(val)}\")\n",
                "    return train, val\n",
                "\n",
                "df_train, df_val = load_and_preprocess()\n",
                "\n",
                "# Feature Engineering\n",
                "df_train['Route'] = df_train['PolCode'].astype(str) + \"_\" + df_train['PodCode'].astype(str) + \"_\" + df_train['ModeOfTransport'].astype(str)\n",
                "df_val['Route'] = df_val['PolCode'].astype(str) + \"_\" + df_val['PodCode'].astype(str) + \"_\" + df_val['ModeOfTransport'].astype(str)\n",
                "\n",
                "FEATURES = ['PolCode', 'PodCode', 'ModeOfTransport', 'Route']\n",
                "TARGET = 'Actual_Duration_Hours'\n",
                "\n",
                "# Label Encoding\n",
                "combined = pd.concat([df_train[FEATURES], df_val[FEATURES]], axis=0)\n",
                "for col in FEATURES:\n",
                "    le = LabelEncoder()\n",
                "    le.fit(combined[col].astype(str))\n",
                "    df_train[col] = le.transform(df_train[col].astype(str))\n",
                "    df_val[col] = le.transform(df_val[col].astype(str))\n",
                "\n",
                "X_train = df_train[FEATURES]\n",
                "y_train = df_train[TARGET]\n",
                "X_val = df_val[FEATURES]\n",
                "y_val = df_val[TARGET]\n",
                "\n",
                "# Log Transform Target\n",
                "y_train_log = np.log1p(y_train)\n",
                "y_val_log = np.log1p(y_val)\n",
                "\n",
                "def calculate_wape(y_true, y_pred):\n",
                "    return np.sum(np.abs(y_true - y_pred)) / np.sum(np.abs(y_true))"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 2. Model Training (4 Models)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "model_results = {}\n",
                "\n",
                "# --- 1. Linear Regression (Baseline) ---\n",
                "print(\"Training Linear Regression...\")\n",
                "lr = LinearRegression()\n",
                "lr.fit(X_train, y_train_log)\n",
                "preds_lr = np.expm1(lr.predict(X_val))\n",
                "model_results['Linear Regression'] = preds_lr\n",
                "\n",
                "# --- 2. Random Forest (simplified) ---\n",
                "print(\"Training Random Forest (Sampled for speed)...\")\n",
                "# Using max_depth=10 and n_estimators=20 to keep it fast on 600k rows\n",
                "rf = RandomForestRegressor(n_estimators=20, max_depth=10, n_jobs=4, random_state=42)\n",
                "rf.fit(X_train, y_train_log)\n",
                "preds_rf = np.expm1(rf.predict(X_val))\n",
                "model_results['Random Forest'] = preds_rf\n",
                "\n",
                "# --- 3. XGBoost ---\n",
                "print(\"Training XGBoost...\")\n",
                "xg_reg = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=1000, learning_rate=0.05, max_depth=10, n_jobs=4)\n",
                "xg_reg.fit(X_train, y_train_log)\n",
                "preds_xgb = np.expm1(xg_reg.predict(X_val))\n",
                "model_results['XGBoost'] = preds_xgb\n",
                "\n",
                "# --- 4. LightGBM ---\n",
                "print(\"Training LightGBM...\")\n",
                "lgb_train = lgb.Dataset(X_train, y_train_log)\n",
                "params = {'objective': 'regression', 'metric': 'rmse', 'num_leaves': 50, 'learning_rate': 0.05, 'verbose': -1}\n",
                "gbm = lgb.train(params, lgb_train, num_boost_round=1000)\n",
                "preds_lgb = np.expm1(gbm.predict(X_val))\n",
                "model_results['LightGBM'] = preds_lgb"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 3. Advanced Evaluation Matrices"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "results_df = []\n",
                "\n",
                "for name, preds in model_results.items():\n",
                "    rmse = np.sqrt(mean_squared_error(y_val, preds))\n",
                "    mae = mean_absolute_error(y_val, preds)\n",
                "    r2 = r2_score(y_val, preds)\n",
                "    acc = 100 * (1 - calculate_wape(y_val, preds))\n",
                "    \n",
                "    results_df.append({\n",
                "        'Model': name,\n",
                "        'Accuracy (1-WAPE)': f\"{acc:.2f}%\",\n",
                "        'RMSE (Hours)': round(rmse, 2),\n",
                "        'MAE (Hours)': round(mae, 2),\n",
                "        'R2 Score': round(r2, 4)\n",
                "    })\n",
                "\n",
                "metrics_table = pd.DataFrame(results_df).set_index('Model')\n",
                "print(metrics_table)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 4. Visualizations"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# A. Mode-wise Error Analysis (Boxplot)\n",
                "# Add predictions to validation df for analysis\n",
                "df_val['Pred_XGB'] = preds_xgb\n",
                "df_val['Abs_Error'] = abs(df_val['Actual_Duration_Hours'] - df_val['Pred_XGB'])\n",
                "\n",
                "# Restore Mode labels for plotting (inverse transform not strictly needed if we map 0,1,2, but cleaner to use original if available. \n",
                "# Here we just reload or use integers. Let's assume 0,1,2 corresponds to the sorted specific modes (Air, Rail, Road).\n",
                "# Ideally we inverse transform, but for now we plot by encoded ID)\n",
                "\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.boxplot(x='ModeOfTransport', y='Abs_Error', data=df_val, showfliers=False)\n",
                "plt.title('Absolute Error Distribution by Transport Mode (XGBoost)')\n",
                "plt.ylabel('Absolute Error (Hours)')\n",
                "plt.xlabel('Mode ID (Encoded)')\n",
                "plt.show()\n",
                "\n",
                "# B. Feature Importance (XGBoost)\n",
                "xgb.plot_importance(xg_reg, importance_type='gain', max_num_features=10, title='Feature Importance (Gain)', height=0.5)\n",
                "plt.show()\n",
                "\n",
                "# C. Prediction vs Actual (Heteroscedasticity Check)\n",
                "plt.figure(figsize=(10, 6))\n",
                "sns.scatterplot(x=y_val, y=preds_xgb, alpha=0.1, color='blue')\n",
                "plt.plot([0, y_val.max()], [0, y_val.max()], 'r--', lw=2)\n",
                "plt.xlabel('Actual Hours')\n",
                "plt.ylabel('Predicted Hours')\n",
                "plt.title('XGBoost: Predicted vs Actual')\n",
                "plt.show()\n",
                "\n",
                "# D. Residual Histogram\n",
                "plt.figure(figsize=(10, 6))\n",
                "residuals = y_val - preds_xgb\n",
                "sns.histplot(residuals, bins=50, kde=True, color='purple')\n",
                "plt.title('Residual Distribution (Errors)')\n",
                "plt.xlabel('Residual (Actual - Pred)')\n",
                "plt.show()"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.8.5"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}